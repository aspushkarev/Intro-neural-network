{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Radial Basis Network"
      ],
      "metadata": {
        "id": "NNa3puSuQ3Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.losses import binary_crossentropy"
      ],
      "metadata": {
        "id": "BIqz9EJlYPcR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pUatDat7O0Ov"
      },
      "outputs": [],
      "source": [
        "class RBFLayer(Layer):\n",
        "    def __init__(self, units, gamma, **kwargs):\n",
        "        super(RBFLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gamma = K.cast_to_floatx(gamma)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "#         print(input_shape)\n",
        "#         print(self.units)\n",
        "        self.mu = self.add_weight(name='mu',\n",
        "                                  shape=(int(input_shape[1]), self.units),\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "        super(RBFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        diff = K.expand_dims(inputs) - self.mu\n",
        "        l2 = K.sum(K.pow(diff, 2), axis=1)\n",
        "        res = K.exp(-1 * self.gamma * l2)\n",
        "        return res\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.units)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom non-trainable keras layers"
      ],
      "metadata": {
        "id": "oiagd6yNUqcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('/content/k49-train-imgs.npz')['arr_0']\n",
        "y = np.load('/content/k49-train-labels.npz')['arr_0']\n",
        "y = (y <= 25).astype(int)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(RBFLayer(10, 0.5))\n",
        "model.add(Dense(1, activation='sigmoid', name='foo'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss=binary_crossentropy)"
      ],
      "metadata": {
        "id": "ut7X2djkUr-v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size=256, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmq9VyQ5WtuZ",
        "outputId": "a45c880b-8726-4443-ea57-13dcb6a7367c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "908/908 [==============================] - 18s 19ms/step - loss: 0.6821\n",
            "Epoch 2/3\n",
            "908/908 [==============================] - 16s 18ms/step - loss: 0.6805\n",
            "Epoch 3/3\n",
            "908/908 [==============================] - 17s 18ms/step - loss: 0.6805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8a59a9510>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}